home: &home_path /homes/dnogina/code/topology-control # all other paths are relative to home

artifacts_config:
  save_artifacts_to: artifacts 

processor_config:
  skip_processing: false
  dataset_paths:
    raw: &raw_data_path data/raw 
    processed: &processed_data_path data/processed 

  train_val_split: .99

  # Updated point cloud params to match your notebook
  point_cloud_params:
    radius: 0.02
    sigma: 0.02  # Match your notebook's sigma = radius
    mu: 0.0
    n_gaussian: 5  # N = 10 from your notebook
    n_uniform: 50000  # NUM_SAMPLES = 10000 from your notebook

  # Volume processor params for SDF generation
  volume_processor_params:
    device: cpu
    resolution: 50  # Match your notebook's resolution = 50

model_config:
  skip_building: false
  model_name: deepsdf #lipschitz_deepsdf #deepsdf
  # DeepSDF specific parameters matching your notebook
  z_dim: 1 #16  # Z_DIM = 16 from your notebook
  layer_size: 256  # HIDDEN_DIM = 64 from your notebook
  coord_dim: 3  # 3D coordinates
  dropout_p: 0.2  # Match your notebook's dropout_p = 0.2
  
trainer_config:
  skip_training: false
  processed_data_path: *processed_data_path
  dataset_type: sdf #lipschitz_sdf  #sdf 
  lipschitz_lambda: 0.00001
  loss_function: deepsdf  # Use custom DeepSDF loss
  optimizer: adam
  network_learning_rate: 0.001  # lr=1e-3 from your notebook
  latent_learning_rate: 0 #0.01
  batch_size: 8  # BATCH_SIZE = 16 from your notebook
  num_epochs: 1000  # max_epochs=20 from your notebook
  max_points: 300000  # Allow more points for better SDF learning
  
  # DeepSDF specific training parameters
  sdf_delta: 1.0  # DELTA = 1.0 from your notebook
  latent_sd: .01
  latent_mean: 0.0  # LATENT_MEAN = 0 from your notebook
  
  # SDF Dataset configuration - ensure dataset_info is available
  dataset_info:
    processed_data_path: *processed_data_path
    volume_coords_path: null  # Will be set by processor
    train_files: []  # Will be populated by processor
    val_files: []    # Will be populated by processor
    latent_vectors: null  # Will be initialized by trainer
  
  # Model saving
  save_model: true
  save_best_only: true
  save_frequency: 20
  
evaluator_config:
  skip_evaluation: true
  # Evaluation specific configs for mesh extraction
  batch_size: 8
  resolution: 50  # Match training resolution for mesh extraction
  test_data_path: *processed_data_path